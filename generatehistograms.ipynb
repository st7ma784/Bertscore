{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"st7ma784\", \"Bertscore\"\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "metric_to_Grab=[\"F1\"]\n",
    "Group_by=[#\"modelname\",\n",
    "\"modelname\",\n",
    "\"LSAVersion\",\n",
    "#\"perfect_match\",\n",
    "#\"padding_length\"\n",
    "]\n",
    "ignore_values=[\"albert-base-v2\",\"roberta-base\"]\n",
    "data={}\n",
    "options={k:set() for k in Group_by}\n",
    "print(\"Grabbing data:\")\n",
    "run_configs=set()\n",
    "for run in tqdm(runs):\n",
    "       \n",
    "    if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        hist=run.history()\n",
    "        # print(hist)\n",
    "        config=run.config\n",
    "        #print(config)        \n",
    "        sortedkeys=list([str(i) for i in config.keys()])\n",
    "        sortedkeys.sort()\n",
    "        items=list([str(config[i]) for i in sortedkeys])\n",
    "        code=\"_\".join(items)\n",
    "        if not any([item in ignore_values for item in config.items()]) and config[\"batch_size\"]==180 and code not in run_configs:\n",
    "            run_configs.add(code)\n",
    "\n",
    "            dictkeys=list(set(config.keys()).intersection(set(Group_by)))\n",
    "            dictkeys.sort()\n",
    "            for k in dictkeys:\n",
    "                s=options[k]\n",
    "                s.add(config.get(k,\"\"))\n",
    "                options[k]=s\n",
    "            entry_name= \"_\".join([config.get(k,\"\") for k in dictkeys])\n",
    "            #print(entry_name)\n",
    "\n",
    "            dictkeys=set(hist.keys()).intersection(set(metric_to_Grab))\n",
    "            for k in dictkeys:\n",
    "                lis=data.get(entry_name,[])\n",
    "                lis.extend(hist[k])\n",
    "                data[entry_name]=lis\n",
    "    \n",
    "    \n",
    "        # for k in dictkeys:\n",
    "        #     summarydict[k].append(hist[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# %matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure=plt.figure()\n",
    "i=0\n",
    "for key in options:\n",
    "    for entry in options[key]:\n",
    "        #filter data by data.key() includes entry\n",
    "        newdict={k:v for k,v in data.items() if entry in k.split(\"_\")}\n",
    "        figure=plt.figure(i)\n",
    "        i+=1\n",
    "        plot=sns.histplot(data=newdict, kde = True,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof of concept. \n",
    "\n",
    "#We're going to take all runs, and then do a set of configs,\n",
    "\n",
    "#During creation of the set, if there is the same config with 384 and 128 for padding length, we're going to plot a histogram of each set of results. \n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"st7ma784\", \"Bertscore\"\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "metric_to_Grab=[\"F1\"]\n",
    "ignore_values=[\"albert-base-v2\",\"roberta-base\"]\n",
    "data={}\n",
    "print(\"Grabbing data:\")\n",
    "codepairs=[]\n",
    "run_configs=set()\n",
    "for run in tqdm(runs):\n",
    "    if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "        sortedkeys=list([str(i) for i in config.keys()])\n",
    "        sortedkeys.sort()\n",
    "        values=list([str(config[i]) for i in sortedkeys])\n",
    "        code=\"_\".join(values)\n",
    "        if not any([item in ignore_values for item in config.values()]) and config[\"batch_size\"]==180:\n",
    "            run_configs.add(code)\n",
    "for code in run_configs:\n",
    "    othercode=code\n",
    "    if \"128\" in code:\n",
    "        othercode=code.replace(\"128\",\"384\")\n",
    "    elif \"384\" in code:\n",
    "        othercode=code.replace(\"384\",\"128\")\n",
    "    if othercode in run_configs:\n",
    "        codepairs.append((code,othercode))\n",
    "\n",
    "tests={}\n",
    "print(\"saving runs where tests exist\")\n",
    "for run in tqdm(runs):\n",
    "    if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "\n",
    "        sortedkeys=list([str(i) for i in config.keys()])\n",
    "        sortedkeys.sort()\n",
    "        print(sortedkeys)\n",
    "        values=list([str(config[i]) for i in sortedkeys])\n",
    "        code=\"_\".join(values)\n",
    "\n",
    "        if code in chain.from_iterable(codepairs):\n",
    "            newcode=code.replace(\"128\",\"\")\n",
    "            newcode=newcode.replace(\"384\",\"\")\n",
    "            hist=run.history()\n",
    "            \n",
    "            dictkeys=set(hist.keys()).intersection(set(metric_to_Grab))\n",
    "            for k in dictkeys:\n",
    "                lis=tests.get(newcode,{})\n",
    "                code=\"Padding Length = {}\".format(128 if \"128\" in code else 384)\n",
    "                lis[code]=hist[k]\n",
    "                tests[newcode]=lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# %matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "figure=plt.figure()\n",
    "i=0\n",
    "for key in tqdm(tests):\n",
    "    if key.startswith(\"none\"):\n",
    "        figure=plt.figure(i)\n",
    "        i+=1\n",
    "        plot=sns.histplot(data=tests[key], kde = True,)\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to generalise the above code block to allow us to generate graphs of any set of sweep that is comprehensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests={}\n",
    "print(\"saving runs where tests exist\")\n",
    "for run in tqdm(runs):\n",
    "    if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "\n",
    "        sortedkeys=list([str(i) for i in config.keys()])\n",
    "        sortedkeys.sort()\n",
    "        # print(sortedkeys)\n",
    "        values=list([str(config[i]) for i in sortedkeys])\n",
    "        code=\"_\".join(values)\n",
    "        for group in codesets:\n",
    "            if code in group[1]:\n",
    "                key=group[0]\n",
    "                args=code.split(\"_\")\n",
    "                argindex=sortedkeys.index(key)\n",
    "                value=code.split(\"_\")[argindex]\n",
    "                first=args[:argindex] if argindex>0 else []\n",
    "                last=args[argindex:] if argindex != len(args)-1 else []\n",
    "                testname=\"_\".join(first+last)\n",
    "\n",
    "                hist=run.history()\n",
    "            \n",
    "                dictkeys=set(hist.keys()).intersection(set(metric_to_Grab))\n",
    "                for k in dictkeys:\n",
    "                    lis=tests.get(testname,{})\n",
    "                    code=\"{} = {}\".format(key,value)\n",
    "                    lis[code]=hist[k]\n",
    "                    tests[testname]=lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 601/860 [00:06<00:02, 94.09it/s] "
     ]
    }
   ],
   "source": [
    "#proof of concept. \n",
    "\n",
    "#We're going to take all runs, and then do a set of configs,\n",
    "\n",
    "#During creation of the set, if there is the same config with 384 and 128 for padding length, we're going to plot a histogram of each set of results. \n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"st7ma784\", \"Bertscore\"\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "metric_to_Grab=[\"F1\"]\n",
    "ignore_values=[]#\"albert-base-v2\",\"roberta-base\"]\n",
    "keys_of_interest=set([\"LSAVersion\",\"all_layers\",\"modelname\",\"padding_length\",\"perfect_match\"])\n",
    "data={}\n",
    "print(\"Grabbing data:\")\n",
    "codepairs=[]\n",
    "run_configs=set()\n",
    "keyvaluesets={}\n",
    "\n",
    "'''Code to find all runs that have completed'''\n",
    "for run in tqdm(runs):\n",
    "    #if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "\n",
    "        sortedkeys=list([str(i) for i in config.keys() if i in keys_of_interest])\n",
    "        sortedkeys.sort()\n",
    "        values={i:config[i] for i in sortedkeys if i in keys_of_interest}\n",
    "        values[\"perfect_match\"]= not values[\"perfect_match\"] # fix the error in code :-(\n",
    "        values=list([str(values[i]) for i in sortedkeys])\n",
    "        \n",
    "        for k,v in zip(sortedkeys,values):\n",
    "            valueset=set(keyvaluesets.get(k,[]))\n",
    "            valueset.add(v)\n",
    "            keyvaluesets[k]=list(valueset)\n",
    "        code=\"_\".join(values)\n",
    "        if not any([item in ignore_values for item in config.values()]) and config[\"batch_size\"]==180:\n",
    "            run_configs.add(code)\n",
    "\n",
    "'''\n",
    "A code block that searches each key that show the unique affect of a key in a set of runs.     \n",
    "'''\n",
    "for item in keyvaluesets.items():\n",
    "    print(item)\n",
    "codesets=[]\n",
    "for run in tqdm(runs):\n",
    "    #if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "        sortedkeys=list([str(i) for i in config.keys() if i in keys_of_interest])\n",
    "        sortedkeys.sort()\n",
    "        for i,key in enumerate(sortedkeys):\n",
    "            #get all values of key\n",
    "            possible_values=keyvaluesets[key]\n",
    "            codes=[]\n",
    "            for v in possible_values:\n",
    "                codes.append(list([str(config[i]) if i!=key else v for i in sortedkeys]))       \n",
    "            codes=[\"_\".join(code) for code in codes]\n",
    "            # print(codes)\n",
    "            if all([code in run_configs for code in codes]):\n",
    "                codesets.append((key,tuple(codes)))\n",
    "\n",
    "#remove duplicates in codesets\n",
    "                \n",
    "codesets=list(set(codesets))\n",
    "# for s in codesets:\n",
    "#     print(s)#Gather data\n",
    "tests={}\n",
    "print(\"saving runs where tests exist\")\n",
    "for run in tqdm(runs):\n",
    "    #if run.state == \"finished\" or run.summary.get(\"e_F1\",-1)>0: #other check for all logging complete \n",
    "        config=run.config\n",
    "\n",
    "        sortedkeys=list([str(i) for i in config.keys() if i in keys_of_interest])\n",
    "        sortedkeys.sort()\n",
    "        # print(sortedkeys)\n",
    "        values={i:config[i] for i in sortedkeys if i in keys_of_interest}\n",
    "        values['perfect_match']= not values['perfect_match'] # fix the error in code :-(\n",
    "        runcode=\"_\".join(list([str(values[i]) for i in sortedkeys]))\n",
    "        for group in codesets:\n",
    "            if runcode in group[1]:\n",
    "                key=group[0]\n",
    "                testname=\"_\".join([str(values[i]) for i in sortedkeys if i in keys_of_interest and i!=key])\n",
    "                hist=run.history()\n",
    "                dictkeys=set(hist.keys()).intersection(set(metric_to_Grab))\n",
    "                for k in dictkeys:\n",
    "                    lis=tests.get(testname,{})\n",
    "                    code=\"{} = {}\".format(key,values[key])\n",
    "                    lis[code]=hist[k]\n",
    "                    tests[testname]=lis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\st7ma\\Miniconda3\\envs\\open-ce\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# %matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "dir=\"./graphs\"\n",
    "import os\n",
    "os.makedirs(dir,exist_ok=True)\n",
    "for i,key in tqdm(enumerate(tests)):\n",
    "    #if (\"bert-base-uncased\") in key:\n",
    "        figure=plt.figure(i)\n",
    "        plot=sns.histplot(data=tests[key], kde = True,)\n",
    "        figure.suptitle(key)\n",
    "        #escape keys\n",
    "        name=key.replace(\"/\",\"-\")\n",
    "\n",
    "        #save figure\n",
    "\n",
    "        plt.savefig(os.path.join(dir,'{}.svg'.format(name)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
